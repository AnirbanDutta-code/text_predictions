{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d895dd7",
   "metadata": {},
   "source": [
    "## importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9c939e-5a48-4814-a2d9-2a39b456d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 13:34:32.698975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-15 13:34:32.886680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-15 13:34:33.966250: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/satam/all_pro2/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,LSTM, Dense\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ef7e8a-fc8d-4792-85f4-52ade1929eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"qoute_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a57012",
   "metadata": {},
   "source": [
    "## prepearing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df00218-cf4b-45a3-9093-b30a7f49499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote=df['quote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902d6a9b-86cd-4f5b-852a-f2114bc04f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cef2801-a7f6-40a5-881f-3cdaf97b5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = quote.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f01a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "quote = quote.str.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988b7b7",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669c42de-d6de-484d-98a8-f0b375d5dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=8978\n",
    "Tokenizer=Tokenizer(num_words=vocab_size)\n",
    "Tokenizer.fit_on_texts(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3885a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8978\n"
     ]
    }
   ],
   "source": [
    "print(len(Tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9c310",
   "metadata": {},
   "source": [
    "### save tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078796e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 359295 bytes\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save it properly\n",
    "with open('Tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(Tokenizer, f)\n",
    "\n",
    "# Verify it was saved (optional)\n",
    "import os\n",
    "print(f\"File size: {os.path.getsize('Tokenizer.pkl')} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031523bb-8f25-4df7-b346-34208159b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = Tokenizer.texts_to_sequences(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae6680e-8f26-4a79-bf94-2a1e528d375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq in sequences:\n",
    "  for i in range(1,len(seq)):\n",
    "    input_seq = seq[:i]\n",
    "    output_seq = seq[i]\n",
    "    X.append(input_seq)\n",
    "    y.append(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ab35ca-1700-4757-875a-4cf469291da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(x) for x in X)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7f8351-873d-4d4b-80ad-ba31fbdbffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = pad_sequences(X, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4c0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "290ddcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e780001a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], shape=(1, 8978))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9812e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "rnn_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684548d",
   "metadata": {},
   "source": [
    "## making model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "801226cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "728588e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "rnn_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c369ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satam/all_pro2/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rnn_model.add(\n",
    "    Embedding(input_dim=vocab_size,output_dim=embedding_dim, input_length=max_len)\n",
    ")\n",
    "rnn_model.add(\n",
    "    SimpleRNN(units=rnn_units)\n",
    ")\n",
    "rnn_model.add(\n",
    "    Dense(units=vocab_size,activation=\"softmax\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a7c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a1869ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a947f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
    ")\n",
    "lstm_model.add(LSTM(units=rnn_units))\n",
    "lstm_model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "     \n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cce60723",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbeecb",
   "metadata": {},
   "source": [
    "## WARNING UNCOMMENT THIS IF YOU WANT  TO TRAIN MODEL IN YOUR MACHINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c52c510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model.fit(\n",
    "#     X_padded,\n",
    "#     y_one_hot,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aba54a",
   "metadata": {},
   "source": [
    "## predecting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70577ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word={index: word for word, index in Tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54bc67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "lstm_model = load_model(\"/home/satam/Downloads/lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfb72fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predection(model,text,tokenizer,max_len):\n",
    "    text=text.lower()\n",
    "    seq1=tokenizer.texts_to_sequences([text])[0]\n",
    "    seq=pad_sequences([seq1],maxlen=max_len,padding='pre')\n",
    "    ##predictions\n",
    "    # print(seq1)\n",
    "    \n",
    "    predict=model.predict(seq,verbose=0)\n",
    "    predect_index=np.argmax(predict)\n",
    "    # print(f'predict{predict}')\n",
    "    return index_to_word[predect_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49f7abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implying\n"
     ]
    }
   ],
   "source": [
    "seed = \"are you \"\n",
    "generate_text = predection(lstm_model,seed,Tokenizer,max_len)\n",
    "print(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cc5c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,seed_text,max_len,n_words):\n",
    "  for _ in range(n_words):\n",
    "    next_word = predection(model,seed_text,tokenizer,max_len)\n",
    "    if next_word == \"\":\n",
    "      break\n",
    "    seed_text += \" \" + next_word\n",
    "  return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89dd605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you a  thousand times i wrote the less if it does not\n"
     ]
    }
   ],
   "source": [
    "seed = \"are you a \"\n",
    "generated_tex = generate_text(lstm_model,Tokenizer,seed,max_len,10)\n",
    "print(generated_tex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_pro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
