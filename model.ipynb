{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475fb6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 13:17:59.456094: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-15 13:17:59.484575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-15 13:18:00.553347: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/satam/all_pro2/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,LSTM, Dense\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e54aaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "lstm_model = load_model(\"/home/satam/Downloads/lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a318d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=745\n",
    "import pickle\n",
    "\n",
    "with open('/home/satam/facial/tokenizer.pkl', 'rb') as f:\n",
    "    Tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word={index: word for word, index in Tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d7082f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predection(model,text,tokenizer,max_len):\n",
    "    texts=text.lower()\n",
    "    seq1=tokenizer.texts_to_sequences([texts])[0]\n",
    "    seq=pad_sequences([seq1],maxlen=max_len,padding='pre')\n",
    "    ##predictions\n",
    "    # print(seq1)\n",
    "    \n",
    "    predict=model.predict(seq,verbose=0)\n",
    "    predect_index=np.argmax(predict)\n",
    "    # print(f'predict{predict}')\n",
    "    return index_to_word[predect_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155bdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6709be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thousand\n"
     ]
    }
   ],
   "source": [
    "seed = \"are you a \"\n",
    "generated_tex = predection(lstm_model,seed,Tokenizer,max_len)\n",
    "print(generated_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fb48709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,seed_text,max_len,n_words):\n",
    "  for _ in range(n_words):\n",
    "    next_word = predection(model,seed_text,tokenizer,max_len)\n",
    "    if next_word == \"\":\n",
    "      break\n",
    "    seed_text += \" \" + next_word\n",
    "  return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02f9b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you a  thousand times i wrote the less if it does not\n"
     ]
    }
   ],
   "source": [
    "seed = \"are you a \"\n",
    "generated_tex = generate_text(lstm_model,Tokenizer,seed,max_len,10)\n",
    "print(generated_tex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_pro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
